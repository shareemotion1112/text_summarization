Generalization from limited examples, usually studied under the umbrella of meta-learning, equips learning techniques with the ability to adapt quickly in dynamical environments and proves to be an essential aspect of lifelong learning.

In this paper, we introduce the Projective Subspace Networks (PSN), a deep learning paradigm that learns non-linear embeddings from limited supervision.

In contrast to previous studies, the embedding in PSN deems samples of a given class to form an affine subspace.

We will show that such modeling leads to robust solutions, yielding competitive results on supervised and semi-supervised few-shot classification.

Moreover, our PSN approach has the ability of end-to-end learning.

In contrast to previous works, our projective subspace can be thought of as a richer representation capturing higher-order information datapoints for modeling new concepts.

@highlight

We proposed Projective Subspace Networks for few-shot and semi-supervised few-shot learning

@highlight

This paper proposes a new embedding-based approach for the problem of few-shot learning and an extension to this model to the semi-supervised few-shot learning setting.

@highlight

New method for fully and semi-supervised few-shot classification based on learning a general embedding and then learning a subspace of it for each class